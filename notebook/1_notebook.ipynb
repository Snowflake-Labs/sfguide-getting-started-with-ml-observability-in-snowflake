{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4d192a-ebd2-41f7-a992-55e5e40c68bc",
   "metadata": {
    "collapsed": false,
    "name": "Title",
    "resultHeight": 943
   },
   "source": [
    "![](https://www.snowflake.com/wp-content/themes/snowflake/assets/img/brand-guidelines/logo-sno-blue-example.svg)\n",
    "\n",
    "# Build, Deploy and Monitor your Model in Snowflake\n",
    "\n",
    "In this demo we will be showcasing how a complete model life cycle looks like in Snowflake. We will be using the following capabilities in Snowflake,\n",
    "\n",
    "* Snowflake ML Python SDK\n",
    "* Model Registry\n",
    "* ML Observability\n",
    "* Alerts + Stored Procedures\n",
    "\n",
    "![](https://drive.google.com/file/d/1jWryVEAjyetHMRgTTMo_bnx_BZRdeNuC/view?usp=sharing)\n",
    "\n",
    ">**Use case:** A bank has been dealing with loss of customers to competition. They want to understand the likelihood of each of their customer's churning so that they can take necessary action for users with high probablity of churning.\n",
    "\n",
    "### **Features**\n",
    "\n",
    "* **CREDITSCORE:** Credit score of the customer based on their historical credit behavior and management  \n",
    "* **GEOGRAPHY:** Country of residence\n",
    "* **GENDER:** Gender of the customer\n",
    "* **AGE:** Age of the customer\n",
    "* **TENURE:** Duration in years that they have been a customer\n",
    "* **BALANCE:** Current balance of their bankaccount\n",
    "* **NUMOFPRODUCTS:** Number of products purchased from the bank\n",
    "* **HASCRCARD:** Does the customer have a credit card? - 1 if they do, 0 if they don't\n",
    "* **ISACTIVEMEMBER:** Has the customer used their bank account in the last 3 months? - 1 if they did, 0 if they didn't\n",
    "* **ESTIMATEDSALARY:** Estimated salary of the customer\n",
    "* **DEBTTOINCOME:** Debt to income ratio\n",
    "\n",
    "### **Model**\n",
    "\n",
    "We will build a classification model using XGBoost framework within Snowflake ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "importheaders",
    "resultHeight": 54
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "from datetime import datetime, timedelta\n",
    "from snowflake.ml.registry import Registry\n",
    "import joblib\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import snowflake.ml.modeling.preprocessing as pp\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.snowpark.types import StringType, IntegerType\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, random, floor,current_date, datediff\n",
    "\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"mlops_customerchurn\", \"version\":{\"major\":1, \"minor\":0}}\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "solution_prefix = session.get_current_warehouse()\n",
    "solution_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51a542-d06f-42fc-ad28-2f408f940b04",
   "metadata": {
    "collapsed": false,
    "name": "load_data",
    "resultHeight": 46
   },
   "source": [
    "### Load synthetic data from the data_stage into a Snowflake table using a COPY INTO command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8a2ccd3-075f-4a1e-9ab0-00e248cc9e4e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "initial_customer_dataset",
    "resultHeight": 111
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total exited customers: 1714 (Target: ~2000)\n",
      "   CustomerId  Surname  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
      "0           1    Johns          402    France    Male   55       9   91944.03   \n",
      "1           2  Schultz          735     Spain    Male   59       8  126536.56   \n",
      "2           3    Jones          570     Spain    Male   54       7  191357.66   \n",
      "3           4    Baker          406    France  Female   73       3  125263.00   \n",
      "4           5  Aguirre          371     Spain    Male   88       9  195626.75   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1         36899.18       0   \n",
      "1              2          0               0         33120.74       0   \n",
      "2              2          1               1         34751.09       1   \n",
      "3              4          0               0        169844.77       0   \n",
      "4              4          0               1         13787.72       0   \n",
      "\n",
      "  TransactionTimestamp  debttoincome  \n",
      "0  2022-01-09 14:08:54            23  \n",
      "1  2022-04-19 06:29:13            80  \n",
      "2  2022-07-11 11:43:59            29  \n",
      "3  2022-12-03 05:38:57            24  \n",
      "4  2022-10-30 09:17:13            80  \n"
     ]
    }
   ],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "    \n",
    "CREATE OR REPLACE STAGE data_stage\n",
    "    FILE_FORMAT = (TYPE = 'CSV') \n",
    "    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/mlops_customerchurn.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @data_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5283d28-3f4b-4247-93c3-43dc4e305315",
   "metadata": {
    "collapsed": false,
    "name": "read_file",
    "resultHeight": 46
   },
   "source": [
    "### Read a CSV file using Snowpark from a stage in Snowflake into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a349023c-8855-4b60-8bdd-35ec51c48141",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "CUSTOMERS_DATA",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "spdf = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@data_stage\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e0e09-a79a-4fc5-8620-a8504782ec44",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "simulatedates",
    "resultHeight": 350
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, to_date,lit\n",
    "\n",
    "# Step 1: Get today's date\n",
    "todays_date = datetime.now()\n",
    "\n",
    "latest_date = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n",
    "\n",
    "# Step 3: Calculate the difference in days\n",
    "diff_days = (todays_date - latest_date).days - 1\n",
    "\n",
    "df = spdf.with_column(\n",
    "    \"TRANSACTIONTIMESTAMP\", \n",
    "    dateadd(\"day\", lit(diff_days), col(\"TRANSACTIONTIMESTAMP\"))\n",
    ")\n",
    "\n",
    "df.show()\n",
    "\n",
    "# If you need to update the table in Snowflake:\n",
    "df.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4b2b17b-ba3b-4eb0-b302-585f066f87ab",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "remove_rownum",
    "resultHeight": 350
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMERID\"  |\"CREDITSCORE\"  |\"GEOGRAPHY\"  |\"GENDER\"  |\"AGE\"  |\"TENURE\"  |\"BALANCE\"  |\"NUMOFPRODUCTS\"  |\"HASCRCARD\"  |\"ISACTIVEMEMBER\"  |\"ESTIMATEDSALARY\"  |\"EXITED\"  |\"TRANSACTIONTIMESTAMP\"  |\"DEBTTOINCOME\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1             |402            |France       |Male      |55     |9         |91944.03   |1                |1            |1                 |36899.18           |0         |2022-01-09 14:08:54     |23              |\n",
      "|2             |735            |Spain        |Male      |59     |8         |126536.56  |2                |0            |0                 |33120.74           |0         |2022-04-19 06:29:13     |80              |\n",
      "|3             |570            |Spain        |Male      |54     |7         |191357.66  |2                |1            |1                 |34751.09           |1         |2022-07-11 11:43:59     |29              |\n",
      "|4             |406            |France       |Female    |73     |3         |125263.0   |4                |0            |0                 |169844.77          |0         |2022-12-03 05:38:57     |24              |\n",
      "|5             |371            |Spain        |Male      |88     |9         |195626.75  |4                |0            |1                 |13787.72           |0         |2022-10-30 09:17:13     |80              |\n",
      "|6             |320            |Germany      |Male      |72     |7         |28858.19   |3                |1            |0                 |48456.88           |0         |2023-11-26 06:10:34     |95              |\n",
      "|7             |421            |Spain        |Male      |71     |6         |15990.69   |3                |1            |0                 |191619.44          |1         |2022-10-02 08:53:11     |49              |\n",
      "|8             |766            |Spain        |Male      |39     |4         |39715.24   |1                |0            |1                 |22544.05           |0         |2022-01-17 10:34:53     |76              |\n",
      "|9             |514            |Spain        |Male      |44     |6         |193003.03  |3                |1            |1                 |16901.08           |0         |2022-01-15 01:31:26     |52              |\n",
      "|10            |630            |France       |Female    |64     |6         |189832.56  |3                |1            |1                 |83592.57           |0         |2023-12-09 06:53:42     |56              |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf= df.drop('ROWNUMBER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f72cd-5892-4656-ae23-3db6ffb1cd8e",
   "metadata": {
    "collapsed": false,
    "name": "preprocessing",
    "resultHeight": 66
   },
   "source": [
    "#### Define a preprocessing pipeline using Pipeline with two steps: Ordinal Encoding for categorical columns and Min-Max Scaling for numerical columns. It then splits the data into training and testing sets, applies the preprocessing steps to the training data, and saves the pipeline as a joblib file (preprocessing_pipeline.joblib) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92413c3-0dea-4d98-a70a-0c77c72b0397",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "preprocessing_pipeline",
    "resultHeight": 287
   },
   "outputs": [],
   "source": [
    "num_cols = ['ESTIMATEDSALARY', 'BALANCE', 'CREDITSCORE','AGE','TENURE','DEBTTOINCOME']\n",
    "output_cols=['EstimatedSalary_SS', 'Balance_SS', 'CreditScore_SS','Age_SS','Tenure_SS','debttoincome_SS']\n",
    "\n",
    "cat_cols = ['HasCrCard', 'IsActiveMember', 'Geography','Gender', 'NumOfProducts']\n",
    "string_columns = ['GEOGRAPHY', 'GENDER']\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "            (\n",
    "                \"OE\",\n",
    "                pp.OrdinalEncoder(\n",
    "                    input_cols=string_columns,\n",
    "                    output_cols=string_columns,\n",
    "                )\n",
    "                \n",
    "            ),\n",
    "            (\n",
    "                \"MMS\",\n",
    "                pp.MinMaxScaler(\n",
    "                    clip=True,\n",
    "                    input_cols=num_cols,\n",
    "                    output_cols=output_cols,\n",
    "                    drop_input_cols= True,\n",
    "                )\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "\n",
    "PIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\n",
    "joblib.dump(preprocessing_pipeline, PIPELINE_FILE) # We are just pickling it locally first\n",
    "training, testing = spdf.random_split(weights=[0.8, 0.2], seed=111)\n",
    "training_spdf = preprocessing_pipeline.fit(training).transform(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5deeba5-4197-4a01-b93a-c797cbe13925",
   "metadata": {
    "collapsed": false,
    "name": "save_pipeline",
    "resultHeight": 47
   },
   "source": [
    "#### Store the pipeline file in a stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6772-3e92-49c1-a969-6f8a03ba7c8a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "ml_stage",
    "resultHeight": 354
   },
   "outputs": [],
   "source": [
    "session.sql(\"CREATE or replace stage ML_STAGE\").collect()\n",
    "session.file.put(PIPELINE_FILE, \"@ML_STAGE\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15b984-9294-4e35-a76e-1e6210653ed9",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "view_stage",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "ls @ML_STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bc115-40c0-4012-a5f5-c0a92b28e0fa",
   "metadata": {
    "collapsed": false,
    "name": "build_model",
    "resultHeight": 60
   },
   "source": [
    "## Build the XGBClassifier model and train using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7af4a413-9d63-497e-a7a3-237553a363e1",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____initial_training",
    "resultHeight": 671
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.dataframe.DataFrame at 0x33cc21a60>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n",
    "\n",
    "cat_cols = ['HasCrCard', 'IsActiveMember', 'Geography','Gender', 'NumOfProducts']\n",
    "# Split dataset into training and testing \n",
    "#training, testing = spdf.random_split(weights=[0.8, 0.2], seed=111)\n",
    "Target = [\"EXITED\"]\n",
    "\n",
    "feature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\"]]\n",
    "\n",
    "# Define the output column name for the predicted label\n",
    "output_label = [\"PREDICTED_CHURN\"]\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a XGBClassifier object with input, label, and output column names\n",
    "model = XGBClassifier(\n",
    "    input_cols=feature_names_input,\n",
    "    label_cols=Target,\n",
    "    output_cols=output_label,\n",
    ")\n",
    "\n",
    "# Train the classifier model using the training set\n",
    "_ = model.fit(training_spdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86a6fb-7dba-4ba0-91b7-a0428301b3f2",
   "metadata": {
    "collapsed": false,
    "name": "cell6",
    "resultHeight": 46
   },
   "source": [
    "### Initalize Snowflake Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b1cba-2e57-4508-9601-9955ac7a830e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____log_model",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.model import type_hints\n",
    "\n",
    "reg = Registry(session=session)\n",
    "\n",
    "MODEL_NAME = \"QS_CustomerChurn_classifier\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "\n",
    "mv = reg.log_model(model,\n",
    "                   model_name=MODEL_NAME,\n",
    "                   version_name=MODEL_VERSION,\n",
    "                   options={'relax_version': False},\n",
    "                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\n",
    "reg.show_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bde85-0531-4ec5-b0ac-6b3baf7502fd",
   "metadata": {
    "collapsed": false,
    "name": "cell7",
    "resultHeight": 60
   },
   "source": [
    "## Stored Procedure for carrying ongoing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709bd3d-7c4d-4bc3-aa99-ba3ea627ec31",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inference_utils",
    "resultHeight": 432
   },
   "outputs": [],
   "source": [
    "from snowflake import snowpark\n",
    "from snowflake.ml.registry import Registry\n",
    "import joblib\n",
    "import os\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import snowflake.ml.modeling.preprocessing as pp\n",
    "from snowflake.snowpark.types import StringType, IntegerType\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "def inference_sp(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n",
    "    reg = Registry(session=session)\n",
    "    m = reg.get_model(modelname)  # Fetch the model using the registry\n",
    "    mv = m.version(modelversion)\n",
    "    input_table_name=table_name\n",
    "    \n",
    "    # Load preprocessing pipeline from a file\n",
    "    session.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\n",
    "    PIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib.gz'\n",
    "    \n",
    "    database=session.get_current_database()\n",
    "    \n",
    "    schema=session.get_current_schema()\n",
    "    column_check_sql = f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "    WHERE TABLE_NAME = '{input_table_name}'  \n",
    "    AND COLUMN_NAME = 'PREDICTED_CHURN'\n",
    "    AND TABLE_SCHEMA = '{schema}' \n",
    "    AND TABLE_CATALOG = '{database}';\n",
    "    \"\"\"\n",
    "    \n",
    "    column_exists = session.sql(column_check_sql).collect()[0][0]\n",
    "\n",
    "    # Only add the column if it doesn't exist\n",
    "    if column_exists == 0:\n",
    "        session.sql(f'ALTER TABLE {input_table_name} ADD COLUMN PREDICTED_CHURN INT').collect()\n",
    "    \n",
    "    # Check if the file was downloaded successfully\n",
    "    if not os.path.exists(PIPELINE_FILE):\n",
    "        raise FileNotFoundError('Preprocessing pipeline not found in /tmp directory')\n",
    "    \n",
    "    \n",
    "    # Load preprocessing pipeline from the downloaded file\n",
    "    preprocessing_pipeline = joblib.load(PIPELINE_FILE)  # Load the preprocessing pipeline\n",
    "    \n",
    "    # Read the temporary DataFrame\n",
    "    df = session.table(input_table_name)\n",
    "    df = df.with_column(\"PREDICTED_CHURN\", F.lit(9999))\n",
    "    \n",
    "    df.write.save_as_table(\"CUSTOMERCHURN_PREDICTIONS_OUTPUT\", mode='append')\n",
    "    # Apply the preprocessing pipeline to the input DataFrame\n",
    "    testing_spdf = preprocessing_pipeline.fit(df).transform(df)\n",
    "    \n",
    "    # Perform prediction using the model\n",
    "    results = mv.run(testing_spdf, function_name=\"predict\")  # 'results' is the output DataFrame with predictions\n",
    "   \n",
    "    temp_results_table = \"TEMP_PREDICTION_RESULTS\"\n",
    "    results.write.save_as_table(temp_results_table, mode='overwrite')\n",
    "    \n",
    "    update_sql = f\"\"\"\n",
    "    UPDATE CUSTOMERCHURN_PREDICTIONS_OUTPUT t\n",
    "    SET PREDICTED_CHURN = r.PREDICTED_CHURN\n",
    "    FROM TEMP_PREDICTION_RESULTS r\n",
    "    WHERE t.CUSTOMERID = r.CUSTOMERID;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the update statement\n",
    "    session.sql(update_sql).collect()\n",
    "\n",
    "    update_sql1 = f\"\"\"\n",
    "    UPDATE {input_table_name} t\n",
    "    SET PREDICTED_CHURN = r.PREDICTED_CHURN\n",
    "    FROM TEMP_PREDICTION_RESULTS r\n",
    "    WHERE t.CUSTOMERID = r.CUSTOMERID\n",
    "    AND t.TRANSACTIONTIMESTAMP=r.TRANSACTIONTIMESTAMP ;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the update statement\n",
    "    session.sql(update_sql1).collect()\n",
    "\n",
    "    return \"Success\"\n",
    "\n",
    "# Register the stored procedure\n",
    "session.sproc.register(\n",
    "    func=inference_sp,\n",
    "    name=\"inference_sp\",\n",
    "    replace=True,\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@ML_STAGE\",\n",
    "    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n",
    "    return_type=StringType()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc9d6e-599b-466b-adf9-a5b8cb1a4752",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "save_testdata",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "testing.write.save_as_table(\"customer_churn\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd54bf0-f700-4219-9fa1-9aac33ca4a9d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "run_inference",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "CALL inference_sp('CUSTOMERS','QS_CUSTOMERCHURN_CLASSIFIER', 'v1');\n",
    "CALL inference_sp('CUSTOMER_CHURN','QS_CUSTOMERCHURN_CLASSIFIER', 'v1');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce8079-4ddd-41df-a8cb-b867deb7098b",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Monitoring",
    "resultHeight": 115
   },
   "source": [
    "# Enable Monitoring\n",
    "Create a model monitor using the CREATE MODEL MONITOR command. The monitor object automatically refreshes the monitor logs by querying source data and updates the monitoring reports based on the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047644f-ab0a-4447-b573-2afd3c20f739",
   "metadata": {
    "language": "python",
    "name": "DEMO____ADD_MONITOR",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL=QS_CustomerChurn_classifier\n",
    "    VERSION=v1\n",
    "    FUNCTION=predict\n",
    "    SOURCE=CUSTOMER_CHURN\n",
    "    BASELINE=CUSTOMERS\n",
    "    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n",
    "    ACTUAL_CLASS_COLUMNS=(EXITED)\n",
    "    ID_COLUMNS=(CUSTOMERID)\n",
    "    WAREHOUSE=ML_WH\n",
    "    REFRESH_INTERVAL='1 min'\n",
    "    AGGREGATION_WINDOW='1 day';\n",
    "\"\"\"\n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e6b74-699e-4b7a-b281-0aa6ca925b79",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Dashboard",
    "resultHeight": 83
   },
   "source": [
    "Open the Dashboard by navigating to Studio->Models\n",
    "\n",
    "Click on your model and choose the monitor that you just added above.Change the date range to \"Last 12 months\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
